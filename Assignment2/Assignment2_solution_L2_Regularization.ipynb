{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWvDL80f8khB",
        "outputId": "a9d24d16-b5ac-4269-91b7-a6b383613e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(9630)\n",
        "tf.random.set_seed(9630)\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goNTLx1Y8vMV",
        "outputId": "2b517ea3-41e7-4a90-9a54-d7f3d25cf080"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLkdbyRT8xRL"
      },
      "outputs": [],
      "source": [
        "size_input = 784\n",
        "size_hidden = [128, 64]\n",
        "size_output = 10\n",
        "number_of_train_examples = 60000\n",
        "number_of_test_examples = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90IEcGRz8zA0"
      },
      "outputs": [],
      "source": [
        "# load datasets\n",
        "mnist = tf.keras.datasets.mnist\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Th5Cfbv58053"
      },
      "outputs": [],
      "source": [
        "def mnist_normalize():\n",
        "  (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "  X_train = np.reshape(X_train, (X_train.shape[0], 784)) / 255.\n",
        "  X_test = np.reshape(X_test, (X_test.shape[0], 784)) / 255.\n",
        "  y_train = tf.keras.utils.to_categorical(y_train)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "def fashion_normalize():\n",
        "  (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "  X_train = np.reshape(X_train, (X_train.shape[0], 784)) / 255.\n",
        "  X_test = np.reshape(X_test, (X_test.shape[0], 784)) / 255.\n",
        "  y_train = tf.keras.utils.to_categorical(y_train)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  return (X_train, y_train), (X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUcIZ_rF83L7"
      },
      "outputs": [],
      "source": [
        "# Split dataset into batches\n",
        "# (X_train, y_train), (X_test, y_test) = mnist_normalize()\n",
        "(X_train, y_train), (X_test, y_test) = fashion_normalize()\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSeWjfQo85Vh"
      },
      "outputs": [],
      "source": [
        "# Define class to build MLP model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device = None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer (2)\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. \n",
        "    If None, the device will automatically decide during Eager Execution ('gpu')\n",
        "    \"\"\"\n",
        "\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "\n",
        "    # Initialize weights of input layer\n",
        "    self.W0 = tf.Variable(tf.random.normal([self.size_input, self.size_input]))\n",
        "    # Initialize biases for input layer\n",
        "    self.b0 = tf.Variable(tf.random.normal([1, self.size_input]))\n",
        "    # Initialize weights between input layer and hidden layer 1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer 1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "    # Initialize weights between hidden layer 1 and hidden layer 2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer 2\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "    # Initialize weights between hidden layer 2 and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "\n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W0, self.W1, self.W2, self.W3, self.b0, self.b1, self.b2, self.b3]\n",
        "\n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device == 'gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "    return self.y\n",
        "\n",
        "  def loss(self, y_pred, y_true):\n",
        "    \"\"\"\n",
        "    y_pred: Tensor of shape (batch_size, size_output)\n",
        "    y_true: Tensor of shape (batch_size, size_output)\n",
        "    \"\"\"\n",
        "\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.mean_squared_error(y_true_tf, y_pred_tf)\n",
        "\n",
        "  def loss_with_regularization(self, y_pred, y_true, lambd = 0.7):\n",
        "    m = y_true.shape[1]\n",
        "    W0 = self.variables[0]\n",
        "    W1 = self.variables[1]\n",
        "    W2 = self.variables[2]\n",
        "    W3 = self.variables[3]\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      pre_loss = self.loss(predicted, y_train)\n",
        "    L2_regularization_loss = lambd * (np.sum(np.square(W0)) + np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3))) / (2 * m)\n",
        "    final_loss = pre_loss + L2_regularization_loss\n",
        "\n",
        "    return final_loss\n",
        "\n",
        "  def backward_with_regularization(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate = 1e-3)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss_with_regularization(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "\n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "\n",
        "    # Cast X to float 32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    # Remember to normalize your dataset before moving forward\n",
        "\n",
        "    # Compute values in input layer\n",
        "    # what0 = tf.matmul(X_tf, self.W0) + self.b0\n",
        "    # hhat0 = tf.nn.relu(what0)\n",
        "\n",
        "    # Compute values in hidden layer 1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "\n",
        "    # Compute values in hidden layer 2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    output = tf.nn.softmax(output)\n",
        "\n",
        "    # Now consider two things\n",
        "    # First, look at inbuild loss functions if they work with softmax and then change this\n",
        "    # Second, add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofZ8bduA9ACl"
      },
      "source": [
        "#Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YNS-5rm8-KN"
      },
      "outputs": [],
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EXBcqhq9CfU"
      },
      "outputs": [],
      "source": [
        "def compute_acc(y_pred, y_true):\n",
        "  maxid = lambda x: np.argmax(x)\n",
        "  y_pred_max = np.array([maxid(i) for i in y_pred])\n",
        "  y_true_max = np.array([maxid(j) for j in y_true])\n",
        "  acc = sum(y_pred_max == y_true_max) / len(y_pred_max)\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_std(y_pred):\n",
        "  y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "  std_dev = np.std(y_pred_tf)\n",
        "  std_err = std_dev / np.sqrt(len(y_pred_tf))\n",
        "  variance = std_dev**2\n",
        "  return std_err, variance"
      ],
      "metadata": {
        "id": "k7gc2jZRs22o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emYJFPPz9E-e",
        "outputId": "cddbe584-7cea-4f75-8810-5b2e91b9d5b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch: 1 - Average MSE: 5749763.822933333\n",
            "                   - Accuracy: 0.49508333333333376\n",
            "Number of Epoch: 2 - Average MSE: 5774463.249066667\n",
            "                   - Accuracy: 0.8080333333333333\n",
            "Number of Epoch: 3 - Average MSE: 5803651.345066667\n",
            "                   - Accuracy: 0.8824166666666676\n",
            "Number of Epoch: 4 - Average MSE: 5835331.447466667\n",
            "                   - Accuracy: 0.9063499999999999\n",
            "Number of Epoch: 5 - Average MSE: 5865088.0682666665\n",
            "                   - Accuracy: 0.917450000000001\n",
            "Number of Epoch: 6 - Average MSE: 5891383.842133333\n",
            "                   - Accuracy: 0.92505\n",
            "Number of Epoch: 7 - Average MSE: 5914759.9872\n",
            "                   - Accuracy: 0.9304999999999995\n",
            "Number of Epoch: 8 - Average MSE: 5934680.200533333\n",
            "                   - Accuracy: 0.9352500000000009\n",
            "Number of Epoch: 9 - Average MSE: 5948664.490666667\n",
            "                   - Accuracy: 0.9393000000000012\n",
            "Number of Epoch: 10 - Average MSE: 5956097.365333334\n",
            "                   - Accuracy: 0.9424333333333332\n",
            "\n",
            "Total time taken (in seconds): 2683.48\n"
          ]
        }
      ],
      "source": [
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_hidden, size_output, device = 'gpu')\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  acc = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(9630)).batch(40)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_gpu.loss_with_regularization(preds, outputs)\n",
        "    mlp_on_gpu.backward_with_regularization(inputs, outputs)\n",
        "    acc = acc + compute_acc(preds, outputs)\n",
        "  print('Number of Epoch: {} - Average MSE: {}' .format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "  print('                   - Accuracy: {}' .format(acc/len(train_ds)))\n",
        " \n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "# For per epoch_time\n",
        "# epoch_time = Total time / Number of epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5-xBFUc9GgZ"
      },
      "source": [
        "#Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQO42uif9HN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7003f75-451f-4831-f402-de9987af4bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 0.0260\n",
            "Accuracy: 0.8694\n"
          ]
        }
      ],
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "# test_loss_total = 0.0\n",
        "test_acc = 0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  # b = mlp_on_gpu.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_gpu.loss(preds, outputs)\n",
        "  test_acc = test_acc + compute_acc(preds, outputs)\n",
        "  err, var = compute_std(preds)\n",
        "  \n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))\n",
        "print('Accuracy: {}' .format(test_acc/len(test_ds)))\n",
        "print('Standard Error: {}' .format(err))\n",
        "print('Variance: {}' .format(var))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 Trials - Fashion MNIST"
      ],
      "metadata": {
        "id": "Bjkx4FIwDYsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_fashion = []\n",
        "accuracy_fashion = []\n",
        "err_fashion = []\n",
        "var_fashion = []\n",
        "for i in range(10):\n",
        "  test_loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  test_acc = 0\n",
        "  test_err = 0\n",
        "  test_var = 0\n",
        "  test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(25).batch(40)\n",
        "  for inputs, outputs in test_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    test_loss_total = test_loss_total + mlp_on_gpu.loss_with_regularization(preds, outputs)\n",
        "    mlp_on_gpu.backward_with_regularization(inputs, outputs)\n",
        "    test_acc = test_acc + compute_acc(preds, outputs)\n",
        "    test_err = test_err + compute_std(preds)[0]\n",
        "    test_var = test_var + compute_std(preds)[1]\n",
        "  mse_fashion.append(np.sum(test_loss_total) / X_test.shape[0])\n",
        "  accuracy_fashion.append(test_acc/len(test_ds))\n",
        "  err_fashion.append(test_err/len(test_ds))\n",
        "  var_fashion.append(test_var/len(test_ds))\n",
        "  print('Number of Trial: {} - Average MSE: {}' .format(i + 1, np.sum(test_loss_total) / X_test.shape[0]))\n",
        "  print('                   - Accuracy: {}' .format(test_acc/len(test_ds)))\n",
        "  print('                   - Standard Error: {}' .format(test_err/len(test_ds)))\n",
        "  print('                   - Variance: {}' .format(test_var/len(test_ds)))\n",
        " \n",
        "print(mse_fashion)\n",
        "print(accuracy_fashion)\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgfdlQ-38Jxq",
        "outputId": "5dcba532-e74c-4188-dd94-8da624d16336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Trial: 1 - Average MSE: 5957405.0816\n",
            "                   - Accuracy: 0.8669000000000009\n",
            "Number of Trial: 2 - Average MSE: 5957627.0848\n",
            "                   - Accuracy: 0.8683999999999998\n",
            "Number of Trial: 3 - Average MSE: 5957738.9056\n",
            "                   - Accuracy: 0.8690999999999998\n",
            "Number of Trial: 4 - Average MSE: 5957738.9056\n",
            "                   - Accuracy: 0.8674000000000001\n",
            "Number of Trial: 5 - Average MSE: 5957735.2192\n",
            "                   - Accuracy: 0.8683999999999998\n",
            "Number of Trial: 6 - Average MSE: 5957732.7616\n",
            "                   - Accuracy: 0.8682000000000005\n",
            "Number of Trial: 7 - Average MSE: 5957756.5184\n",
            "                   - Accuracy: 0.8676\n",
            "Number of Trial: 8 - Average MSE: 5958223.0528\n",
            "                   - Accuracy: 0.8684\n",
            "Number of Trial: 9 - Average MSE: 5959062.7328\n",
            "                   - Accuracy: 0.8693999999999994\n",
            "Number of Trial: 10 - Average MSE: 5959101.6448\n",
            "                   - Accuracy: 0.8682999999999998\n",
            "[5957405.0816, 5957627.0848, 5957738.9056, 5957738.9056, 5957735.2192, 5957732.7616, 5957756.5184, 5958223.0528, 5959062.7328, 5959101.6448]\n",
            "[0.8669000000000009, 0.8683999999999998, 0.8690999999999998, 0.8674000000000001, 0.8683999999999998, 0.8682000000000005, 0.8676, 0.8684, 0.8693999999999994, 0.8682999999999998]\n",
            "\n",
            "Total time taken (in seconds): 3171.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(np.mean(accuracy_fashion))\n",
        "# print(np.var(accuracy_fashion))\n",
        "# plt.plot(accuracy_fashion, label = 'mean:0.87, var:5.06e-07')\n",
        "# plt.legend(loc='upper right', bbox_to_anchor = (1,1.25))\n",
        "# plt.xlabel('Accuracy')\n",
        "# plt.ylabel('Count')\n",
        "# plt.title('L2 Regularization - Fashion MNIST')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "1NsS3DxoYF9i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 Trials - MNIST"
      ],
      "metadata": {
        "id": "wYKTUqM7DcUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_mnist = []\n",
        "accuracy_mnist = []\n",
        "err_mnist = []\n",
        "var_mnist = []\n",
        "for i in range(10):\n",
        "  test_loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  test_acc = 0\n",
        "  test_err = 0\n",
        "  test_var = 0\n",
        "  test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(25).batch(40)\n",
        "  for inputs, outputs in test_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    test_loss_total = test_loss_total + mlp_on_gpu.loss_with_regularization(preds, outputs)\n",
        "    mlp_on_gpu.backward_with_regularization(inputs, outputs)\n",
        "    test_acc = test_acc + compute_acc(preds, outputs)\n",
        "    test_err = test_err + compute_std(preds)[0]\n",
        "    test_var = test_var + compute_std(preds)[1]\n",
        "  mse_mnist.append(np.sum(test_loss_total) / X_test.shape[0])\n",
        "  accuracy_mnist.append(test_acc/len(test_ds))\n",
        "  err_mnist.append(test_err/len(test_ds))\n",
        "  var_mnist.append(test_var/len(test_ds))\n",
        "  print('Number of Trial: {} - Average MSE: {}' .format(i + 1, np.sum(test_loss_total) / X_test.shape[0]))\n",
        "  print('                   - Accuracy: {}' .format(test_acc/len(test_ds)))\n",
        "  print('                   - Standard Error: {}' .format(test_err/len(test_ds)))\n",
        "  print('                   - Variance: {}' .format(test_var/len(test_ds)))\n",
        " \n",
        "print(mse_mnist)\n",
        "print(accuracy_mnist)\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2znwUNHlDda1",
        "outputId": "f9b896f9-2f72-4f70-e683-2283870ac885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Trial: 1 - Average MSE: 5763265.3312\n",
            "                   - Accuracy: 0.9486999999999988\n",
            "Number of Trial: 2 - Average MSE: 5763272.704\n",
            "                   - Accuracy: 0.9481999999999992\n",
            "Number of Trial: 3 - Average MSE: 5763290.3168\n",
            "                   - Accuracy: 0.9483999999999987\n",
            "Number of Trial: 4 - Average MSE: 5763291.5456\n",
            "                   - Accuracy: 0.9498999999999984\n",
            "Number of Trial: 5 - Average MSE: 5763296.8704\n",
            "                   - Accuracy: 0.9481999999999989\n",
            "Number of Trial: 6 - Average MSE: 5763310.7968\n",
            "                   - Accuracy: 0.9484999999999992\n",
            "Number of Trial: 7 - Average MSE: 5763328.4096\n",
            "                   - Accuracy: 0.9492999999999991\n",
            "Number of Trial: 8 - Average MSE: 5763359.1296\n",
            "                   - Accuracy: 0.9494999999999988\n",
            "Number of Trial: 9 - Average MSE: 5763363.6352\n",
            "                   - Accuracy: 0.9488999999999985\n",
            "Number of Trial: 10 - Average MSE: 5763363.6352\n",
            "                   - Accuracy: 0.9490999999999987\n",
            "[5763265.3312, 5763272.704, 5763290.3168, 5763291.5456, 5763296.8704, 5763310.7968, 5763328.4096, 5763359.1296, 5763363.6352, 5763363.6352]\n",
            "[0.9486999999999988, 0.9481999999999992, 0.9483999999999987, 0.9498999999999984, 0.9481999999999989, 0.9484999999999992, 0.9492999999999991, 0.9494999999999988, 0.9488999999999985, 0.9490999999999987]\n",
            "\n",
            "Total time taken (in seconds): 3290.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(np.mean(accuracy_mnist))\n",
        "# print(np.var(accuracy_mnist))\n",
        "# plt.plot(accuracy_mnist, label = 'mean:0.95, var:2.98e-07')\n",
        "# plt.legend(loc='upper right', bbox_to_anchor = (1,1.25))\n",
        "# plt.xlabel('Accuracy')\n",
        "# plt.ylabel('Count')\n",
        "# plt.title('L2 Regularization - MNIST')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "lDv9NVXrYNls"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Dhka44BelfvU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Assignment2_solution_L2_Regularization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}