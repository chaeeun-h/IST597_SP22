{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxtoQYDYWN0p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# np.random.seed(9630)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Things to do\n",
        "\n",
        "* Remember to Normalize your data and create validation split from train set.\n",
        "* Learn about tf.data, tf.slices and also tf.records"
      ],
      "metadata": {
        "id": "-f4D2XfpZqYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_val = x_train[50000:60000]\n",
        "x_train = x_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "x_train = x_train.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
        "x_val = x_val.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
        "x_test = x_test.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
        "y_train = tf.one_hot(y_train, depth=10)\n",
        "y_val = tf.one_hot(y_val, depth=10)\n",
        "y_test = tf.one_hot(y_test, depth=10)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(128)\n",
        "train_dataset_full = train_dataset.shuffle(buffer_size=1024).batch(len(train_dataset))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(128)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(128)\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "id": "IKyy_VD4WX-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "306a4d2f-f8d2-4f8a-b9fc-9a6aef7ccfdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "391\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create your custom CNN class\n",
        "\n",
        "* Convolution layers has 4D weights of size (h,w,input_feature, output_feature), where h=height of your kernel and w = width of our kernel. If you add batches then it is 5D.\n",
        "* Now your model will convolve across your input feature map with kernel and create output feature map, that is then passed to next layer.\n",
        "* As we have learned in our prior class, to initialize your weights, we use tf.Variable(weight_init(size)), tf.keras.layers.Conv2D will do this for you. Play with the function and see how it works for your problem.\n",
        "* Few important concepts, learn to save your model after every k epochs and start re-training from last checkpoint. This is very useful, and you don't need to retrain your model from scratch."
      ],
      "metadata": {
        "id": "EJaJ2xNOZwLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Normalization for CNN\n",
        "\n",
        "class BNLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, dim, epsilon=10e-8, momentum=0.99):\n",
        "        super(BNLayer, self).__init__()\n",
        "\n",
        "        self.epsilon = epsilon\n",
        "        self.momentum = momentum\n",
        "        self.dim = dim\n",
        "\n",
        "        self.it_call = 0\n",
        "        self.batch_size = 0\n",
        "\n",
        "        self.mu = self.add_weight(\"mu\", shape=[self.dim,], \n",
        "                                initializer=\"zeros\",\n",
        "                                trainable=False)\n",
        "        self.var = self.add_weight(\"var\", shape=[self.dim,], \n",
        "                                   initializer=\"zeros\",\n",
        "                                   trainable=False)\n",
        "\n",
        "        self.gamma = self.add_weight(\"gamma\", shape=[1, self.dim],\n",
        "                                     initializer=\"random_normal\",\n",
        "                                     trainable=True)\n",
        "        self.beta = self.add_weight(\"beta\", shape=[1, self.dim],\n",
        "                                    initializer=\"random_normal\",\n",
        "                                    trainable=True)\n",
        "        \n",
        "    \n",
        "    def call(self, inputs, is_training=True):\n",
        "        \"\"\"forward\n",
        "        BN(x) = gamma * ((x - mu) / sqrt(var + epsilon)) + beta\n",
        "        \"\"\"\n",
        "\n",
        "        if is_training:   # is_training == True: compute BN \n",
        "            if self.batch_size == 0:\n",
        "                self.batch_size = inputs.shape[0]\n",
        "            \n",
        "            batch_mu = tf.math.reduce_mean(inputs, axis=(0,1,2))\n",
        "            batch_var = tf.math.reduce_variance(inputs, axis=(0,1,2))\n",
        "            \n",
        "            normalized_inputs = tf.math.divide((inputs - batch_mu), tf.math.sqrt(batch_var + self.epsilon))\n",
        "            bn_inputs = tf.math.multiply(self.gamma, normalized_inputs) + self.beta\n",
        "\n",
        "            # update mu and var\n",
        "            if inputs.shape[0] == self.batch_size:\n",
        "                running_mu = batch_mu\n",
        "                running_var = batch_var\n",
        "            else:\n",
        "                # the last batch in training may have sample less than batch size\n",
        "                running_mu = batch_mu / inputs.shape[0] * self.batch_size\n",
        "                running_var = batch_var / inputs.shape[0] * self.batch_size\n",
        "            \n",
        "            cur_mu = running_mu * (self.momentum) + self.mu * (1 - (self.momentum))\n",
        "            self.mu.assign(cur_mu)\n",
        "            cur_var = running_var * (self.momentum) + self.var * (1 - (self.momentum))\n",
        "            self.var.assign(cur_var)\n",
        "\n",
        "\n",
        "        else: # is_training == False\n",
        "            normalized_inputs = tf.math.divide((inputs - self.mu), tf.math.sqrt(self.var + self.epsilon))\n",
        "            bn_inputs = tf.math.multiply(self.gamma, normalized_inputs) + self.beta\n",
        "        \n",
        "        return bn_inputs"
      ],
      "metadata": {
        "id": "gHBzfhtlHgE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageRecognitionCNN(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes, device='cpu:0', checkpoint_directory=None):\n",
        "        ''' Define the parameterized layers used during forward-pass, the device\n",
        "            where you would like to run the computation (GPU, TPU, CPU) on and the checkpoint\n",
        "            directory.\n",
        "            \n",
        "            Args:\n",
        "                num_classes: the number of labels in the network.\n",
        "                device: string, 'cpu:n' or 'gpu:n' (n can vary). Default, 'cpu:0'.\n",
        "                checkpoint_directory: the directory where you would like to save or \n",
        "                                      restore a model.\n",
        "        ''' \n",
        "        super(ImageRecognitionCNN, self).__init__()\n",
        "        \n",
        "        # Initialize layers\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, 3,padding='same', activation=None)\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.conv4 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        # self.pool2 = tf.keras.layers.MaxPool2D()\n",
        "        # self.conv5 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        # self.pool2 = tf.keras.layers.MaxPool2D()\n",
        "        # self.conv6 = tf.keras.layers.Conv2D(64, 3, 2, padding='same', activation=None)\n",
        "        # self.conv7 = tf.keras.layers.Conv2D(64, 1, padding='same', activation=None)\n",
        "        self.conv8 = tf.keras.layers.Conv2D(num_classes, 1, padding='same', activation=None)\n",
        "        self.bn = BNLayer(64)\n",
        "        \n",
        "        # Define the device \n",
        "        self.device = device\n",
        "        \n",
        "        # Define the checkpoint directory\n",
        "        self.checkpoint_directory = checkpoint_directory\n",
        "        self.acc = tf.keras.metrics.Accuracy()\n",
        "\n",
        "\n",
        "    def predict(self, images, training):\n",
        "        \"\"\" Predicts the probability of each class, based on the input sample.\n",
        "            \n",
        "            Args:\n",
        "                images: 4D tensor. Either an image or a batch of images.\n",
        "                training: Boolean. Either the network is predicting in\n",
        "                          training mode or not.\n",
        "        \"\"\"\n",
        "        x = self.conv1(images)\n",
        "        # x = self.bn(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        # x = self.bn(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        # x = self.bn(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        # x = self.bn(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv8(x)\n",
        "        #x = tf.nn.relu(x)\n",
        "        #print(x.shape)\n",
        "        x = tf.reshape(x, (-1, 1, 10))\n",
        "        #x = tf.keras.layers.Flatten(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    def loss_fn(self, images, target, training):\n",
        "        \"\"\" Defines the loss function used during \n",
        "            training.         \n",
        "        \"\"\"\n",
        "        preds = self.predict(images, training)\n",
        "        #print(preds.shape)\n",
        "        #print(target.shape)\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=preds)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def grads_fn(self, images, target, training):\n",
        "        \"\"\" Dynamically computes the gradients of the loss value\n",
        "            with respect to the parameters of the model, in each\n",
        "            forward pass.\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self.loss_fn(images, target, training)\n",
        "        return tape.gradient(loss, self.variables)\n",
        "    \n",
        "    def restore_model(self):\n",
        "        \"\"\" Function to restore trained model.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            # Run the model once to initialize variables\n",
        "            dummy_input = tf.constant(tf.zeros((1,48,48,1)))\n",
        "            dummy_pred = self.predict(dummy_input, training=False)\n",
        "            # Restore the variables of the model\n",
        "            saver = tf.Saver(self.variables)\n",
        "            saver.restore(tf.train.latest_checkpoint\n",
        "                          (self.checkpoint_directory))\n",
        "    \n",
        "    def save_model(self, global_step=0):\n",
        "        \"\"\" Function to save trained model.\n",
        "        \"\"\"\n",
        "        tf.Saver(self.variables).save(self.checkpoint_directory, \n",
        "                                       global_step=global_step)   \n",
        "    \n",
        "    # def compute_accuracy(self, input_data):\n",
        "    #     \"\"\" Compute the accuracy on the input data.\n",
        "    #     \"\"\"\n",
        "    #     with tf.device(self.device):\n",
        "    #         #acc = tf.metrics.Accuracy()\n",
        "    #         for step ,(images, targets) in enumerate(input_data):\n",
        "    #             # Predict the probability of each class\n",
        "    #             #print(targets.shape)\n",
        "    #             logits = self.predict(images, training=False)\n",
        "    #             # Select the class with the highest probability\n",
        "    #             #print(logits.shape)\n",
        "    #             logits = tf.nn.softmax(logits)\n",
        "    #             logits = tf.reshape(logits, [-1, 10])\n",
        "    #             targets = tf.reshape(targets, [-1,10])\n",
        "    #             preds = tf.argmax(logits, axis=1)\n",
        "                \n",
        "    #             #m1.update_state\n",
        "    #             # Compute the accuracy\n",
        "    #             #print(preds.shape)\n",
        "    #             acc(tf.reshape(targets, preds))\n",
        "    #     return acc\n",
        "\n",
        "    def compute_accuracy_2(self, images, targets):\n",
        "        \"\"\" Compute the accuracy on the input data.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            \n",
        "            # Predict the probability of each class\n",
        "            logits = self.predict(images, training=False)\n",
        "            # Select the class with the highest probability\n",
        "            \n",
        "            logits = tf.nn.softmax(logits)\n",
        "            logits = tf.reshape(logits, [-1, 10])\n",
        "            targets = tf.reshape(targets, [-1,10])\n",
        "            preds = tf.argmax(logits, axis=1)\n",
        "            goal = tf.argmax(targets, axis=1)\n",
        "            self.acc.update_state(goal, preds)\n",
        "            # Compute the accuracy\n",
        "            result = self.acc.result().numpy()\n",
        "        return result\n",
        "\n",
        "  \n",
        "    def fit_fc(self, training_data, eval_data, optimizer, num_epochs=500, \n",
        "            early_stopping_rounds=10, verbose=10, train_from_scratch=False):\n",
        "        \"\"\" Function to train the model, using the selected optimizer and\n",
        "            for the desired number of epochs. You can either train from scratch\n",
        "            or load the latest model trained. Early stopping is used in order to\n",
        "            mitigate the risk of overfitting the network.\n",
        "            \n",
        "            Args:\n",
        "                training_data: the data you would like to train the model on.\n",
        "                                Must be in the tf.data.Dataset format.\n",
        "                eval_data: the data you would like to evaluate the model on.\n",
        "                            Must be in the tf.data.Dataset format.\n",
        "                optimizer: the optimizer used during training.\n",
        "                num_epochs: the maximum number of iterations you would like to \n",
        "                            train the model.\n",
        "                early_stopping_rounds: stop training if the loss on the eval \n",
        "                                       dataset does not decrease after n epochs.\n",
        "                verbose: int. Specify how often to print the loss value of the network.\n",
        "                train_from_scratch: boolean. Whether to initialize variables of the\n",
        "                                    the last trained model or initialize them\n",
        "                                    randomly.\n",
        "        \"\"\" \n",
        "    \n",
        "        if train_from_scratch==False:\n",
        "            self.restore_model()\n",
        "        \n",
        "        # Initialize best loss. This variable will store the lowest loss on the\n",
        "        # eval dataset.\n",
        "        best_loss = 999\n",
        "        \n",
        "        # Initialize classes to update the mean loss of train and eval\n",
        "        train_loss = tf.keras.metrics.Mean('train_loss')\n",
        "        eval_loss = tf.keras.metrics.Mean('eval_loss')\n",
        "        acc_train = tf.keras.metrics.Mean('train_acc')\n",
        "        acc_val = tf.keras.metrics.Mean('val_acc')\n",
        "        \n",
        "        # Initialize dictionary to store the loss history\n",
        "        self.history = {}\n",
        "        self.history['train_loss'] = []\n",
        "        self.history['eval_loss'] = []\n",
        "        self.history['train_acc'] = []\n",
        "        self.history['val_acc'] = []\n",
        "        \n",
        "        # Begin training\n",
        "        with tf.device(self.device):\n",
        "            for i in range(num_epochs):\n",
        "                # Training with gradient descent\n",
        "                # training_data = training_data.shuffle(buffer_size=1024).batch(128)\n",
        "                for step, (images, target) in enumerate(training_data):\n",
        "                    grads = self.grads_fn(images, target, True)\n",
        "                    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "                    \n",
        "                # Compute the loss on the training data after one epoch\n",
        "                for step, (images, target) in enumerate(training_data):\n",
        "                    loss = self.loss_fn(images, target, True)\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_train(accuracy)\n",
        "                    train_loss(loss)\n",
        "                self.history['train_loss'].append(train_loss.result().numpy())\n",
        "                self.history['train_acc'].append(acc_train.result().numpy())\n",
        "                # Reset metrics\n",
        "                train_loss.reset_states()\n",
        "                acc_train.reset_states()\n",
        "                \n",
        "                # Compute the loss on the eval data after one epoch\n",
        "                for step, (images, target) in enumerate(eval_data):\n",
        "                    loss = self.loss_fn(images, target, True)\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_val(accuracy)\n",
        "                    eval_loss(loss)\n",
        "                self.history['eval_loss'].append(eval_loss.result().numpy())\n",
        "                self.history['val_acc'].append(acc_val.result().numpy())\n",
        "                # Reset metrics\n",
        "                eval_loss.reset_states()\n",
        "                acc_val.reset_states()\n",
        "                \n",
        "                # Print train and eval losses\n",
        "                if (i==0) | ((i+1)%verbose==0):\n",
        "                    print('\\nTrain loss at epoch %d: ' %(i+1), self.history['train_loss'][-1])\n",
        "                    print('Train Acc at epoch %d: ' %(i+1), self.history['train_acc'][-1])\n",
        "                    plt.plot(i + 1, self.history['train_loss'][-1], linestyle = '-', marker = 'o', color = 'b', label = 'loss')\n",
        "                    plt.plot(i + 1, self.history['train_acc'][-1], linestyle = '-', marker = 'o', color = 'r', label = 'accuracy')\n",
        "                    \n",
        "                    print('Eval loss at epoch %d: ' %(i+1), self.history['eval_loss'][-1])\n",
        "                    print('Eval Acc at epoch %d: ' %(i+1), self.history['val_acc'][-1])\n",
        "                    \n",
        "\n",
        "                # Check for early stopping\n",
        "                if self.history['eval_loss'][-1]<best_loss:\n",
        "                    best_loss = self.history['eval_loss'][-1]\n",
        "                    count = early_stopping_rounds\n",
        "                else:\n",
        "                    count -= 1\n",
        "                if count==0:\n",
        "                    break\n",
        "\n",
        "            plt.show()    "
      ],
      "metadata": {
        "id": "H3RZoVNXZ0oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path where you want to save/restore the trained variables.\n",
        "checkpoint_directory = 'models_checkpoints/fashion_mnist/'\n",
        "\n",
        "# Use the GPU if available.\n",
        "device = 'gpu:0'\n",
        "\n",
        "# Define optimizer.\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4)\n",
        "\n",
        "#model = ImageRecognitionCNN(num_classes=7, device=device)"
      ],
      "metadata": {
        "id": "i14-xPKeZ6RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Test model\n",
        "\n",
        "seeds = np.random.randint(1000,9999,3)\n",
        "test_accuracy = []\n",
        "\n",
        "for i in seeds:\n",
        "  # Instantiate model. This doesn't initialize the variables yet.\n",
        "  model = ImageRecognitionCNN(num_classes=10, device=device, \n",
        "                                checkpoint_directory=checkpoint_directory)\n",
        "  print('======================= Trial:', i, '=======================')\n",
        "  model.fit_fc(train_dataset, val_dataset, optimizer, num_epochs=20, \n",
        "            early_stopping_rounds=2, verbose=1, train_from_scratch=True)\n",
        "  \n",
        "  accuracy = model.compute_accuracy_2(x_test,y_test)\n",
        "  test_accuracy.append(accuracy)\n",
        "\n",
        "  \n",
        "test_mean = np.mean(test_accuracy)\n",
        "test_var = np.var(test_accuracy)\n",
        "\n",
        "print(f\"the mean of 3 runs is {test_mean}, and the variance is {test_var}\")\n",
        "plt.boxplot(test_accuracy)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "c4rQ4Sv2Z8QT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ebbf3f73-24b1-4d59-b078-6bf524ea9897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================= Trial: 7163 =======================\n",
            "\n",
            "Train loss at epoch 1:  0.53586537\n",
            "Train Acc at epoch 1:  0.87072706\n",
            "Eval loss at epoch 1:  0.5433949\n",
            "Eval Acc at epoch 1:  0.8717046\n",
            "\n",
            "Train loss at epoch 2:  0.3509784\n",
            "Train Acc at epoch 2:  0.87805116\n",
            "Eval loss at epoch 2:  0.3682195\n",
            "Eval Acc at epoch 2:  0.88333225\n",
            "\n",
            "Train loss at epoch 3:  0.2830702\n",
            "Train Acc at epoch 3:  0.8879546\n",
            "Eval loss at epoch 3:  0.30855745\n",
            "Eval Acc at epoch 3:  0.89217\n",
            "\n",
            "Train loss at epoch 4:  0.25079268\n",
            "Train Acc at epoch 4:  0.8953961\n",
            "Eval loss at epoch 4:  0.28444687\n",
            "Eval Acc at epoch 4:  0.8983607\n",
            "\n",
            "Train loss at epoch 5:  0.22731984\n",
            "Train Acc at epoch 5:  0.9008557\n",
            "Eval loss at epoch 5:  0.2669677\n",
            "Eval Acc at epoch 5:  0.90325475\n",
            "\n",
            "Train loss at epoch 6:  0.20818415\n",
            "Train Acc at epoch 6:  0.905391\n",
            "Eval loss at epoch 6:  0.25380287\n",
            "Eval Acc at epoch 6:  0.9075054\n",
            "\n",
            "Train loss at epoch 7:  0.19417503\n",
            "Train Acc at epoch 7:  0.90925705\n",
            "Eval loss at epoch 7:  0.24863489\n",
            "Eval Acc at epoch 7:  0.9110681\n",
            "\n",
            "Train loss at epoch 8:  0.17786184\n",
            "Train Acc at epoch 8:  0.91273177\n",
            "Eval loss at epoch 8:  0.2392733\n",
            "Eval Acc at epoch 8:  0.9144306\n",
            "\n",
            "Train loss at epoch 9:  0.16818549\n",
            "Train Acc at epoch 9:  0.91587204\n",
            "Eval loss at epoch 9:  0.23755331\n",
            "Eval Acc at epoch 9:  0.9173097\n",
            "\n",
            "Train loss at epoch 10:  0.15716976\n",
            "Train Acc at epoch 10:  0.91859645\n",
            "Eval loss at epoch 10:  0.23570405\n",
            "Eval Acc at epoch 10:  0.9199037\n",
            "\n",
            "Train loss at epoch 11:  0.15072905\n",
            "Train Acc at epoch 11:  0.9210581\n",
            "Eval loss at epoch 11:  0.23636968\n",
            "Eval Acc at epoch 11:  0.9222459\n",
            "\n",
            "Train loss at epoch 12:  0.14254361\n",
            "Train Acc at epoch 12:  0.9233225\n",
            "Eval loss at epoch 12:  0.23524287\n",
            "Eval Acc at epoch 12:  0.9243829\n",
            "\n",
            "Train loss at epoch 13:  0.13195299\n",
            "Train Acc at epoch 13:  0.9254046\n",
            "Eval loss at epoch 13:  0.23346846\n",
            "Eval Acc at epoch 13:  0.92646885\n",
            "\n",
            "Train loss at epoch 14:  0.12897736\n",
            "Train Acc at epoch 14:  0.9273296\n",
            "Eval loss at epoch 14:  0.23823012\n",
            "Eval Acc at epoch 14:  0.92819834\n",
            "\n",
            "Train loss at epoch 15:  0.12326392\n",
            "Train Acc at epoch 15:  0.9290027\n",
            "Eval loss at epoch 15:  0.24154735\n",
            "Eval Acc at epoch 15:  0.9298519\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================= Trial: 9026 =======================\n",
            "\n",
            "Train loss at epoch 1:  0.5685748\n",
            "Train Acc at epoch 1:  0.863593\n",
            "Eval loss at epoch 1:  0.57927245\n",
            "Eval Acc at epoch 1:  0.8647793\n",
            "\n",
            "Train loss at epoch 2:  0.3641266\n",
            "Train Acc at epoch 2:  0.8725318\n",
            "Eval loss at epoch 2:  0.38279057\n",
            "Eval Acc at epoch 2:  0.878631\n",
            "\n",
            "Train loss at epoch 3:  0.29999363\n",
            "Train Acc at epoch 3:  0.8835736\n",
            "Eval loss at epoch 3:  0.32761073\n",
            "Eval Acc at epoch 3:  0.88753444\n",
            "\n",
            "Train loss at epoch 4:  0.2615566\n",
            "Train Acc at epoch 4:  0.8907722\n",
            "Eval loss at epoch 4:  0.29606614\n",
            "Eval Acc at epoch 4:  0.8938863\n",
            "\n",
            "Train loss at epoch 5:  0.23747754\n",
            "Train Acc at epoch 5:  0.8965374\n",
            "Eval loss at epoch 5:  0.27934808\n",
            "Eval Acc at epoch 5:  0.8991688\n",
            "\n",
            "Train loss at epoch 6:  0.2181885\n",
            "Train Acc at epoch 6:  0.90136963\n",
            "Eval loss at epoch 6:  0.26904455\n",
            "Eval Acc at epoch 6:  0.90356725\n",
            "\n",
            "Train loss at epoch 7:  0.2000241\n",
            "Train Acc at epoch 7:  0.9054833\n",
            "Eval loss at epoch 7:  0.2571021\n",
            "Eval Acc at epoch 7:  0.9074034\n",
            "\n",
            "Train loss at epoch 8:  0.1892215\n",
            "Train Acc at epoch 8:  0.90895593\n",
            "Eval loss at epoch 8:  0.2534246\n",
            "Eval Acc at epoch 8:  0.91058844\n",
            "\n",
            "Train loss at epoch 9:  0.18113635\n",
            "Train Acc at epoch 9:  0.91193277\n",
            "Eval loss at epoch 9:  0.25183198\n",
            "Eval Acc at epoch 9:  0.91331345\n",
            "\n",
            "Train loss at epoch 10:  0.16718559\n",
            "Train Acc at epoch 10:  0.91464263\n",
            "Eval loss at epoch 10:  0.24591477\n",
            "Eval Acc at epoch 10:  0.9160399\n",
            "\n",
            "Train loss at epoch 11:  0.15704641\n",
            "Train Acc at epoch 11:  0.91723335\n",
            "Eval loss at epoch 11:  0.24351169\n",
            "Eval Acc at epoch 11:  0.9184569\n",
            "\n",
            "Train loss at epoch 12:  0.14777924\n",
            "Train Acc at epoch 12:  0.919593\n",
            "Eval loss at epoch 12:  0.24363369\n",
            "Eval Acc at epoch 12:  0.9207676\n",
            "\n",
            "Train loss at epoch 13:  0.13725448\n",
            "Train Acc at epoch 13:  0.92188615\n",
            "Eval loss at epoch 13:  0.24158303\n",
            "Eval Acc at epoch 13:  0.92300415\n",
            "\n",
            "Train loss at epoch 14:  0.13001104\n",
            "Train Acc at epoch 14:  0.92399\n",
            "Eval loss at epoch 14:  0.24212617\n",
            "Eval Acc at epoch 14:  0.9250146\n",
            "\n",
            "Train loss at epoch 15:  0.12423863\n",
            "Train Acc at epoch 15:  0.9259334\n",
            "Eval loss at epoch 15:  0.24550241\n",
            "Eval Acc at epoch 15:  0.92688626\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================= Trial: 4818 =======================\n",
            "\n",
            "Train loss at epoch 1:  0.5159182\n",
            "Train Acc at epoch 1:  0.87335026\n",
            "Eval loss at epoch 1:  0.5269118\n",
            "Eval Acc at epoch 1:  0.8745851\n",
            "\n",
            "Train loss at epoch 2:  0.3427884\n",
            "Train Acc at epoch 2:  0.8809464\n",
            "Eval loss at epoch 2:  0.36136654\n",
            "Eval Acc at epoch 2:  0.8866946\n",
            "\n",
            "Train loss at epoch 3:  0.28217304\n",
            "Train Acc at epoch 3:  0.8910055\n",
            "Eval loss at epoch 3:  0.30929753\n",
            "Eval Acc at epoch 3:  0.89491105\n",
            "\n",
            "Train loss at epoch 4:  0.2526501\n",
            "Train Acc at epoch 4:  0.89778155\n",
            "Eval loss at epoch 4:  0.28537133\n",
            "Eval Acc at epoch 4:  0.90060484\n",
            "\n",
            "Train loss at epoch 5:  0.2259718\n",
            "Train Acc at epoch 5:  0.90298784\n",
            "Eval loss at epoch 5:  0.26686156\n",
            "Eval Acc at epoch 5:  0.9053644\n",
            "\n",
            "Train loss at epoch 6:  0.21133043\n",
            "Train Acc at epoch 6:  0.90719986\n",
            "Eval loss at epoch 6:  0.26017374\n",
            "Eval Acc at epoch 6:  0.9091063\n",
            "\n",
            "Train loss at epoch 7:  0.19776125\n",
            "Train Acc at epoch 7:  0.91065884\n",
            "Eval loss at epoch 7:  0.2541761\n",
            "Eval Acc at epoch 7:  0.9123185\n",
            "\n",
            "Train loss at epoch 8:  0.19265914\n",
            "Train Acc at epoch 8:  0.9135299\n",
            "Eval loss at epoch 8:  0.25796953\n",
            "Eval Acc at epoch 8:  0.9148018\n",
            "\n",
            "Train loss at epoch 9:  0.17455\n",
            "Train Acc at epoch 9:  0.91601235\n",
            "Eval loss at epoch 9:  0.24614233\n",
            "Eval Acc at epoch 9:  0.9173224\n",
            "\n",
            "Train loss at epoch 10:  0.16375236\n",
            "Train Acc at epoch 10:  0.9184792\n",
            "Eval loss at epoch 10:  0.24337068\n",
            "Eval Acc at epoch 10:  0.91969967\n",
            "\n",
            "Train loss at epoch 11:  0.15241957\n",
            "Train Acc at epoch 11:  0.9207556\n",
            "Eval loss at epoch 11:  0.24151352\n",
            "Eval Acc at epoch 11:  0.921915\n",
            "\n",
            "Train loss at epoch 12:  0.14570771\n",
            "Train Acc at epoch 12:  0.92288357\n",
            "Eval loss at epoch 12:  0.24116577\n",
            "Eval Acc at epoch 12:  0.92394805\n",
            "\n",
            "Train loss at epoch 13:  0.14140202\n",
            "Train Acc at epoch 13:  0.9248286\n",
            "Eval loss at epoch 13:  0.24493472\n",
            "Eval Acc at epoch 13:  0.92571276\n",
            "\n",
            "Train loss at epoch 14:  0.13226041\n",
            "Train Acc at epoch 14:  0.9265498\n",
            "Eval loss at epoch 14:  0.24328709\n",
            "Eval Acc at epoch 14:  0.9274574\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean of 3 runs is 0.9278035163879395, and the variance is 1.64133632551966e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "evZSHK6ei2OH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}